{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('styles/gcpeixoto-book.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método de Newton: Sair pela Tangente sem Perder o Rumo\n",
    "\n",
    "<div class=\"chapter-thumb\">\n",
    "    <div class=\"chapter-oa\">\n",
    "        <h2>Objetivos de aprendizagem</h2>\n",
    "        <ul>\n",
    "        <li>Compreender o funcionamento do método de Newton, seu algoritmo e as condições necessárias para sua aplicação;</li>\n",
    "\t    <li>Aplicar o método de Newton na resolução de equações não lineares;</li>\n",
    "\t    <li>Analisar o comportamento da convergência do método de Newton, sua precisão e limitações;</li>\t    \n",
    "        <li>Reconhecer variantes do Método de Newton para problemas de otimização, bem como o Método de Halley.</li>\n",
    "        </ul>\n",
    "    </div>        \n",
    "    <div class=\"quote-box\">\n",
    "        <p><em>\"Nenhuma grande descoberta jamais foi feita sem um palpite ousado.\" (Isaac Newton)\n",
    "        </p></em>\n",
    "    </div>        \n",
    "</div>\n",
    "\n",
    "O método de Newton, também conhecido como método de Newton-Raphson, é uma técnica iterativa poderosa para encontrar aproximações das raízes de equações não lineares. Sua ideia central é usar a reta tangente à curva da função em um ponto de aproximação inicial para estimar onde essa reta cruza o eixo $x$, fornecendo assim uma nova aproximação.  Esse processo é repetido até que a diferença entre iterações sucessivas seja suficientemente pequena, indicando convergência para uma raiz.\n",
    "\n",
    "Apesar de ser um método rápido e eficiente com convergência quadrática quando a aproximação inicial está suficientemente próxima da raiz, ele também apresenta desafios. Ele exige que a derivada $f’(x)$ esteja disponível e bem comportada. Além disso, se o ponto inicial estiver longe da raiz, ou se a função tiver pontos de inflexão ou derivadas próximas de zero, o método pode divergir ou oscilar. Por isso, é comum combiná-lo com outras técnicas, como a inspeção gráfica ou métodos mais estáveis (como bisseção) para estimar bons pontos iniciais.\n",
    "\n",
    "```{figure} ../figs/newton-ai.png\n",
    "---\n",
    "width: 400px\n",
    "name: fig-newtonai\n",
    "---\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Explicação do algoritmo\n",
    "\n",
    "O processo iterativo do método é dado pela seguinte função de iteração:\n",
    "\n",
    "$$\n",
    "x^{(k)} = \\phi(x^{(k-1)}) = x^{(k-1)} - \\dfrac{ f(x^{(k-1)} )}{ f'(x^{(k-1)}) }, \\ \\ x^{(0)} = x_0, \\ \\ k = 1,2, \\ldots < \\infty, \\ \\ f'(x^{(k-1)}) \\neq 0, \\ \\ \\forall k.\n",
    "$$\n",
    "\n",
    "\n",
    "onde:\n",
    "- $x^{(k-1)}$ é a aproximação atual.\n",
    "- $f(x^{(k-1)})$ é o valor atual da função.\n",
    "- $f'(x^{(k-1)})$ é o valor atual da primeira derivada da função.\n",
    "\n",
    "A ideia é que a interseção da tangente à curva $f(x)$ no ponto $x^{(k-1)}$ com o eixo $x$ forneça uma nova aproximação $x^{(k)}$. O Método de Newton é uma ferramenta essencial no arsenal de métodos numéricos, oferecendo uma abordagem eficiente e poderosa para a solução de uma ampla variedade de problemas matemáticos.\n",
    "\n",
    "O algoritmo funciona da seguinte forma: \n",
    "\n",
    "1. Inicialize $x^{(0)}$ (chute inicial)\n",
    "\n",
    "2. Para $k$ de 1 até $N$:\n",
    "\n",
    "    a. Calcule $f(x^{(k)})$\n",
    "\n",
    "    b. Calcule $f'(x^{(k)})$ (derivada da função no ponto $x^{(k)}$)\n",
    "\n",
    "    c. Se $f'(x^{(k)}) = 0$, retorne erro (derivada zero, o método falha)\n",
    "\n",
    "    d. Calcule $x^{(k)} = \\phi(x^{(k-1)})$ (como o processo iterativo acima)\n",
    "\n",
    "    e. Se $ER(x^{(k)}, x^{(k-1)}) < \\epsilon$, então a solução foi encontrada com a precisão desejada. Retorne $x^{(k)}$.\n",
    "\n",
    "3. Se o número máximo de iterações for atingido, retorne a última aproximação $x^{(k-1)}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação do algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No algoritmo proposto abaixo, a função `newton` requererá 5 argumentos: \n",
    "\n",
    "- a estimativa inicial, representada pela variável `x0`;\n",
    "- a função $f(x)$ propriamente dita, representada por `f`;\n",
    "- a derivada $f'(x)$, representada por `df`;\n",
    "- o erro relativo assumido, representado por `tol`;\n",
    "- o número máximo de iterações $N$ para tentativa de solução, representado por `nmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import inspect, re, numpy as np\n",
    "from matplotlib.pyplot import plot\n",
    "from prettytable import PrettyTable as pt\n",
    "\n",
    "def newton(x0,f,df,tol,N):\n",
    "    \"\"\"Algoritmo para determinação de raízes pelo método de Newton.\n",
    "\n",
    "    Parâmetros: \n",
    "        x0: estimativa inicial\n",
    "        f: string dependendo de uma variável, i.e., a função-alvo\n",
    "            (e.g., 'x**2 - 1', 'x**2*cos(x)', etc.) \n",
    "        df: string dependendo de uma variável, i.e., a derivada da função-alvo\n",
    "        tol: erro desejado (tolerância)\n",
    "        N: número máximo de iterações a repetir\n",
    "\n",
    "    Retorno: \n",
    "        x: aproximação para a raiz da função    \n",
    "    \"\"\"\n",
    "\n",
    "    # construtor de tabela\n",
    "    table = pt()\n",
    "    \n",
    "    # substitui expressões da string pelas chamadas das funções do numpy\n",
    "    f = re.sub('(sin|sinh|cos|cosh|tan|tanh|exp|log|sqrt|log10|arcsin|arccos|arctan|arcsinh|arccosh|arctanh)', r'np.\\1', f)\n",
    "    df = re.sub('(sin|sinh|cos|cosh|tan|tanh|exp|log|sqrt|log10|arcsin|arccos|arctan|arcsinh|arccosh|arctanh)', r'np.\\1', df)\n",
    "    \n",
    "    # identifica a variável independente em f\n",
    "    var = re.search(r'([a-zA-Z][\\w]*) ?([\\+\\-\\/*]|$|\\))', f).group(1)\n",
    "\n",
    "    \n",
    "    # cria função\n",
    "    f = eval('lambda ' + var + ' :' + f)\n",
    "    \n",
    "    # checa se a função é de uma variável, senão lança erro        \n",
    "    try: \n",
    "        len(inspect.getfullargspec(f).args) - 1 > 0\n",
    "    except:\n",
    "        raise ValueError('O código é válido apenas para uma variável.')\n",
    "    finally:\n",
    "        # cria função derivada\n",
    "        df = eval('lambda ' + var + ' :' + df)\n",
    "    \n",
    "    it = 0 # contador de iteracoes\n",
    "    \n",
    "    # cabeçalho de tabela\n",
    "    table.field_names = ['i','x','f(x)','f\\'(x)','ER']\n",
    "\n",
    "    # imprime estimativa inicial\n",
    "    print(f'Estimativa inicial: x0 = {x0:.6f}\\n')  \n",
    "\n",
    "    # Loop \n",
    "    for i in range(0,N):\n",
    "        \n",
    "        x = x0 - f(x0)/df(x0) # funcao de iteracao \n",
    "        \n",
    "        e = abs(x-x0)/abs(x) # erro\n",
    "        \n",
    "        # tabela\n",
    "        # impressão de tabela\n",
    "        table.add_row([i,np.round(x,8),np.round(f(x),8),np.round(df(x),4),f'{e:e}'])\n",
    "        table.align = 'c';      \n",
    "        \n",
    "        if e < tol:\n",
    "            break\n",
    "        x0 = x                \n",
    "        \n",
    "    print(table)\n",
    "       \n",
    "    if i == N:\n",
    "        print(f'Solução não obtida em {N:d} iterações')\n",
    "    else:\n",
    "        print(f'Solução obtida: x = {x:.6f}')\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Playground_ interativo\n",
    "\n",
    "Utilize o _playground_ interativo abaixo para testar o método da bisseção para funções não lineares quaisquer. Como dado de entrada para $f(x)$, utilize funções escritas nos moldes de Python científico como um tipo `str`. Para os parâmetros do intervalo inicial e de erro, utilize `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe\n",
       "    width=\"100%\"\n",
       "    height=\"650\"\n",
       "    src=\"http://127.0.0.1:8082/\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "\n",
       "></iframe>\n"
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1189d2900>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "import re\n",
    "from dash import dcc, html, Input, Output\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import sympy as sp\n",
    "import inspect\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout of the app\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    # Function input\n",
    "    html.Label(\"f(x): \",\n",
    "               style={'display': 'inline-block', 'padding': '5px'}),\n",
    "    dcc.Input(id=\"function-input\",\n",
    "              type=\"text\",\n",
    "              placeholder=\"Insira f(x)...\",\n",
    "              value=\"cosh(x)*cos(x) - 1\",\n",
    "              style={'width': '20%', 'margin-right': '20px'}),\n",
    "    \n",
    "    # Derivative input\n",
    "    html.Label(\"f'(x): \",\n",
    "               style={'display': 'inline-block', 'padding': '5px'}),\n",
    "    dcc.Input(id=\"df-input\",\n",
    "              type=\"text\",\n",
    "              placeholder=\"Insira f'(x)...\",\n",
    "              value=\"-sin(x)*cosh(x) + cos(x)*sinh(x)\",\n",
    "              style={'width': '20%', 'margin-right': '20px'}),\n",
    "    \n",
    "    # Initial guess input\n",
    "    html.Label(\"x0: \",\n",
    "               style={'display': 'inline-block', 'padding': '5px'}),\n",
    "    dcc.Input(id=\"x0-input\",\n",
    "              type=\"number\",\n",
    "              placeholder=\"Insira x0...\",\n",
    "              value=4.3,\n",
    "              style={'width': '10%', 'margin-right': '20px'}),\n",
    "    \n",
    "    # Tolerance input\n",
    "    html.Label(\"eps: \",\n",
    "               style={'display': 'inline-block', 'padding': '5px'}),\n",
    "    dcc.Input(id=\"tol-input\",\n",
    "              type=\"number\",\n",
    "              placeholder=\"Insira a tol. ...\",\n",
    "              value=1e-3,\n",
    "              style={'width': '10%', 'margin-right': '20px'}),\n",
    "    \n",
    "    html.Hr(),\n",
    "    \n",
    "    # Graph to display the Newton's method visualization\n",
    "    dcc.Graph(id=\"newton-graph\"),\n",
    "    \n",
    "    html.Hr(),\n",
    "    \n",
    "    # Information about the method\n",
    "    html.Div(id=\"info-output\")\n",
    "    \n",
    "], style={'font-family': 'Inter'})\n",
    "\n",
    "\n",
    "# Algoritmo de Newton\n",
    "def newton_method(f, f_prime, x0, tol=1e-5, max_iter=100):\n",
    "    \n",
    "    points = []  # List to store Newton's points\n",
    "    \n",
    "    \n",
    "    # substitui expressões da string pelas chamadas das funções do numpy\n",
    "    f = re.sub('(sin|sinh|cos|cosh|tan|tanh|exp|log|sqrt|log10|arcsin|arccos|arctan|arcsinh|arccosh|arctanh)', r'np.\\1', f)\n",
    "    f_prime = re.sub('(sin|sinh|cos|cosh|tan|tanh|exp|log|sqrt|log10|arcsin|arccos|arctan|arcsinh|arccosh|arctanh)', r'np.\\1', f_prime)\n",
    "    \n",
    "    # identifica a variável independente em f\n",
    "    var = re.search(r'([a-zA-Z][\\w]*) ?([\\+\\-\\/*]|$|\\))', f).group(1)\n",
    "\n",
    "    # cria função\n",
    "    f = eval('lambda ' + var + ' :' + f)\n",
    "    \n",
    "    # checa se a função é de uma variável, senão lança erro        \n",
    "    try: \n",
    "        len(inspect.getfullargspec(f).args) - 1 > 0\n",
    "    except:\n",
    "        raise ValueError('O código é válido apenas para uma variável.')\n",
    "    finally:\n",
    "        # cria função derivada\n",
    "        f_prime = eval('lambda ' + var + ' :' + f_prime)\n",
    "    \n",
    "\n",
    "    x = x0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        fx = f(x)\n",
    "        fpx = f_prime(x)\n",
    "        \n",
    "        if fpx == 0:\n",
    "            return None, \"Derivada é zero. Método falhou.\"\n",
    "        \n",
    "        x_new = x - fx / fpx\n",
    "        points.append(x_new)\n",
    "        \n",
    "        if abs(x_new - x) < tol:\n",
    "            break\n",
    "        \n",
    "        x = x_new\n",
    "        \n",
    "    return x, points, f, f_prime\n",
    "\n",
    "# Callback\n",
    "@app.callback(\n",
    "    [Output(\"newton-graph\", \"figure\"),\n",
    "     Output(\"info-output\", \"children\")],\n",
    "    [Input(\"function-input\", \"value\"),\n",
    "     Input(\"df-input\", \"value\"),\n",
    "     Input(\"x0-input\", \"value\"),\n",
    "     Input(\"tol-input\", \"value\")]\n",
    ")\n",
    "def update_newton_graph(func_str, func_prime, x0, tol):\n",
    "    \n",
    "    # Run Newton's method\n",
    "    root, points, func, func_prime  = newton_method(func_str, func_prime, x0, tol)\n",
    "    \n",
    "    if root is None:\n",
    "        return {}, \"O método de Newton não pode ser aplicado.\"\n",
    "    \n",
    "    # Graph\n",
    "    x_vals = np.linspace(x0 - 2, x0 + 2, 400)\n",
    "    y_vals = func(x_vals)\n",
    "    \n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # y = 0 \n",
    "    fig.add_trace(go.Scatter(x=x_vals,\n",
    "                             y=y_vals*0,\n",
    "                             mode='lines', \n",
    "                             name=\"y=0\", \n",
    "                             line=dict(\n",
    "                                 color='#b2b2b2',\n",
    "                                 dash='dash')))\n",
    "    \n",
    "\n",
    "    # Plot the function curve\n",
    "    fig.add_trace(go.Scatter(x=x_vals,\n",
    "                             y=y_vals,\n",
    "                             mode='lines',\n",
    "                             name=\"f(x)\",\n",
    "                             line=dict(color='#4c9265')))\n",
    "    \n",
    "    \n",
    "    # Approximations\n",
    "    points_y = [func(p)*0 for p in points]    \n",
    "    fig.add_trace(go.Scatter(x=points,\n",
    "                             y=points_y,\n",
    "                             mode='markers',\n",
    "                             name=\"Aproximações\",\n",
    "                             marker=dict(\n",
    "                                 color='#000000',\n",
    "                                 symbol='circle',\n",
    "                                 size=8)))\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Tangents\n",
    "    points_y = [func(p) for p in points]\n",
    "    fig.add_trace(go.Scatter(x=points, \n",
    "                             y=points_y, \n",
    "                             mode='markers', \n",
    "                             name=\"f'(x) starts\", \n",
    "                             marker=dict(\n",
    "                                 color='#FF5733', \n",
    "                                 size=8)))\n",
    "    \n",
    "    # Plot the root point\n",
    "    fig.add_trace(go.Scatter(x=[root], \n",
    "                             y=[func(root)], \n",
    "                             mode='markers', \n",
    "                             name=\"Raiz\", \n",
    "                             marker=dict(\n",
    "                                 color='#eeab00', \n",
    "                                 size=10)))\n",
    "    \n",
    "    \n",
    "    # Update the layout of the graph\n",
    "    fig.update_layout(\n",
    "        template='simple_white',\n",
    "        width=600,\n",
    "        height=500,\n",
    "        margin=dict(l=40, r=40, b=10, t=40),\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"f(x)\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Display information about the result\n",
    "    info_text = f\"Raiz encontrada: {root:.6f}\\n\"\n",
    "    info_text += f\"Número de iterações: {len(points)}\"\n",
    "    \n",
    "    return fig, info_text\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=8082)\n",
    "    #app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicações\n",
    "\n",
    "**Exemplo:** Resolva o problema $f(x) = 0$, para $f(x) = -\\text{arccos}(x) + 4\\text{sen}(x) + 1.7$, no intervalo $-0.2 \\le x \\le 1.0$ e $\\epsilon = 10^{-3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa inicial: x0 = -0.100000\n",
      "\n",
      "+----+-------------+-------------+--------+--------------+\n",
      "| i  |      x      |     f(x)    | f'(x)  |      ER      |\n",
      "+----+-------------+-------------+--------+--------------+\n",
      "| 0  |  0.00656144 |  0.16201076 | 3.4999 | 1.624055e+01 |\n",
      "| 1  | -0.03972877 | -0.06940881 | 3.4961 | 1.165156e+00 |\n",
      "| 2  | -0.01987529 |  0.02983116 | 3.499  | 9.989026e-01 |\n",
      "| 3  | -0.02840088 | -0.01278928 | 3.498  | 3.001876e-01 |\n",
      "| 4  | -0.02474469 |  0.00548778 | 3.4985 | 1.477564e-01 |\n",
      "| 5  | -0.02631332 |  -0.0023538 | 3.4983 | 5.961326e-02 |\n",
      "| 6  | -0.02564047 |  0.00100976 | 3.4984 | 2.624162e-02 |\n",
      "| 7  | -0.02592911 | -0.00043314 | 3.4983 | 1.113178e-02 |\n",
      "| 8  | -0.02580529 |  0.00018581 | 3.4983 | 4.798023e-03 |\n",
      "| 9  |  -0.0258584 |  -7.97e-05  | 3.4983 | 2.053976e-03 |\n",
      "| 10 | -0.02583562 |  3.419e-05  | 3.4983 | 8.818630e-04 |\n",
      "+----+-------------+-------------+--------+--------------+\n",
      "Solução obtida: x = -0.025836\n"
     ]
    }
   ],
   "source": [
    "# Chamada da função\n",
    "xm = newton(-0.1,\n",
    "            '-arccos(x) + 4*sin(x) + 1.7',\n",
    "            '4*cos(x) - 1/(1 - x**2)**1/2',\n",
    "            1e-3,\n",
    "            30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo:** Resolva o problema $h(z) = 0$, para $h(z) = -z(1-2z)^{-1} - \\text{tan}(z+1)$, no intervalo $[1,8]$ e $\\epsilon = 10^{-5}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no exemplo anterior, para utilizarmos o método de Newton é preciso saber a derivada da função $h(z)$. Vamos encontrá-la utilizando o módulo de computação simbólica `sympy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2*z/(1 - 2*z)**2 - tan(z + 1)**2 - 1 - 1/(1 - 2*z)\n"
     ]
    }
   ],
   "source": [
    "# Importa variável z como símbolo\n",
    "from sympy.abc import z \n",
    "import sympy as sym\n",
    "\n",
    "# Derivada\n",
    "dh = sym.diff(-z/(1 - 2*z) - sym.tan(z+1))\n",
    "\n",
    "# Impressão\n",
    "print(dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir daí, utilizamos a expressão normalmente na função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa inicial: x0 = 5.000000\n",
      "\n",
      "+---+------------+------------+---------+--------------+\n",
      "| i |     x      |    f(x)    |  f'(x)  |      ER      |\n",
      "+---+------------+------------+---------+--------------+\n",
      "| 0 | 4.75884953 | 0.01963205 | -1.3483 | 5.067411e-02 |\n",
      "| 1 | 4.77341064 | 0.00056164 | -1.3262 | 3.050462e-03 |\n",
      "| 2 | 4.77383412 | 1.173e-05  | -1.3256 | 8.870850e-05 |\n",
      "| 3 | 4.77384296 |  2.4e-07   | -1.3256 | 1.852869e-06 |\n",
      "+---+------------+------------+---------+--------------+\n",
      "Solução obtida: x = 4.773843\n"
     ]
    }
   ],
   "source": [
    "zm = newton(5,\n",
    "            'z/(1 - 2*z) - tan(z+1)',\n",
    "            '-2*z/(1 - 2*z)**2 - tan(z + 1)**2 - 1 - 1/(1 - 2*z)',\n",
    "            1e-5,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare a quantidade de iterações obtidas com o mesmo exemplo resolvido com o algoritmo da bisseção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivação para otimização\n",
    "\n",
    "O método de Newton, originalmente desenvolvido para encontrar raízes de equações, pode ser adaptado com grande eficácia para problemas de otimização. Nesse contexto, seu objetivo é encontrar os pontos críticos de uma função — ou seja, valores onde a derivada é nula e que podem corresponder a mínimos, máximos ou pontos de sela. A ideia central é usar uma aproximação quadrática da função por meio da série de Taylor de segunda ordem. O processo pode ser resumido nos passos a seguir:\n",
    "\n",
    "1. _Função Objetivo_ (FO): seja $f(x)$ uma função escalar diferenciável cujo mínimo queremos encontrar.\n",
    "\n",
    "2. _Expansão de Taylor de Segunda Ordem_: expandimos $f(x)$ em torno de um ponto $x^{(k)}$ usando a série de Taylor até a segunda ordem:\n",
    "   \n",
    "   $$\n",
    "   f(x) \\approx f(x^{(k)}) + f'(x^{(k)}) (x - x^{(k)}) + \\frac{1}{2} f''(x^{(k)}) (x - x^{(k)})^2,\n",
    "   $$\n",
    "   \n",
    "   onde $f'(x^{(k)})$ é a primeira derivada (gradiente) de $f$ em $x^{(k)}$ e $f''(x^{(k)})$ é a segunda derivada (Hessiana) de $f$ em $x^{(k)}$.\n",
    "\n",
    "3. _Condição de otimização_: para encontrar o ponto $x$ que minimiza $f(x)$, devemos encontrar um ponto onde a derivada da função seja zero. Definimos a direção de descida $t$ como $x - x^{(k)}$:\n",
    "   \n",
    "   $$\n",
    "   f(x^{(k+1)}) \\approx f(x^{(k)}) + f'(x^{(k)}) t + \\frac{1}{2} f''(x^{(k)}) t^2\n",
    "   $$\n",
    "   \n",
    "4. _Derivada da expansão_: para minimizar $f(x)$, tomamos a derivada da expressão acima em relação a $t$ e igualamos a zero:\n",
    "   \n",
    "   $$\n",
    "   \\frac{d}{dt}\\left[ f(x^{(k)}) + f'(x^{(k)}) t + \\frac{1}{2} f''(x^{(k)}) t^2 \\right] = 0\n",
    "   $$\n",
    "   \n",
    "   Uma vez que $f(x^{(k)})$ não depende de $t$, é uma constante. Assim obtemos:\n",
    "  \n",
    "   $$\n",
    "   f'(x^{(k)}) + f''(x^{(k)}) t = 0\n",
    "   $$\n",
    "\n",
    "5. _solução para a direção $t$: resolvendo para $t$, temos:\n",
    "   \n",
    "   $$\n",
    "   t = -\\frac{f'(x^{(k)})}{f''(x^{(k)})}\n",
    "   $$\n",
    "\n",
    "6. _Atualização da Iteração_: a próxima aproximação $x^{(k+1)}$ é obtida somando $t$ ao ponto atual $x^{(k)}$:\n",
    "   \n",
    "   $$\n",
    "   x^{(k+1)} = x^{(k)} + t = x^{(k)} - \\frac{f'(x^{(k)})}{f''(x^{(k)})}\n",
    "   $$\n",
    "\n",
    "A derivada $f'(x^{(k)})$ indica a inclinação da função em $x^{(k)}$. A segunda derivada $f''(x^{(k)})$ fornece informações sobre a curvatura da função. Se $f''(x^{(k)}) > 0$, estamos em um ponto onde a função está curvando para cima (mínimo local), enquanto $f''(x^{(k)}) < 0$ indica um ponto onde a função está curvando para baixo (máximo local). O passo $t$ determina a magnitude e a direção do ajuste necessário para aproximar-se do ponto de mínimo (ou máximo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Halley\n",
    "\n",
    "O método de Halley é uma extensão do método de Newton e utiliza até a terceira derivada da função. Enquanto o método de Newton tem convergência quadrática, o método de Halley converge mais rapidamente e alcança convergência cúbica, pois usa mais informações sobre a curvatura da função. De maneira similar ao que já fizemos, vamos derivar a fórmula partindo diretamente da expansão de Taylor:\n",
    "\n",
    "1. _Expansão de Taylor_: expandimos a função $f(x)$ em torno de um ponto $x^{(k)}$:\n",
    "   \n",
    "   $$\n",
    "   f(x) \\approx f(x^{(k)}) + f'(x^{(k)}) (x - x^{(k)}) + \\frac{1}{2} f''(x^{(k)}) (x - x^{(k)})^2 + \\frac{1}{6} f'''(x^{(k)})(x - x^{(k)})^3,\n",
    "   $$\n",
    "\n",
    "2. _Estimativa da raiz_: supondo que $x^{(k+1)} = x^{(k)} + \\Delta x$ é a nova estimativa da raiz, então queremos $f(x^{(k+1)}) = 0 $. Substituindo $\\Delta x = x^{(k+1)} - x^{(k)}$ na expansão de Taylor e igualando a zero, temos:\n",
    "   \n",
    "   $$\n",
    "   f(x^{(k)}) + f'(x^{(k)})\\Delta x + \\frac{1}{2} f''(x^{(k)})(\\Delta x)^2 + \\frac{1}{6} f'''(x^{(k)})(\\Delta x)^3 = 0\n",
    "   $$\n",
    "\n",
    "3. _Isolamento do passo_: a solução para $\\Delta x$ (que nos dá a atualização para $x$) é dada pela fórmula:\n",
    "   \n",
    "   $$\n",
    "   \\Delta x = -\\frac{f(x^{(k)})}{f'(x^{(k)})} \\left( \\frac{2}{2 - \\frac{f(x^{(k)}) f''(x^{(k)})}{f'(x^{(k)})^2}} \\right)\n",
    "   $$\n",
    "\n",
    "4. _Iteração do Método de Halley_: a fórmula iterativa do método de Halley é então:\n",
    "   \n",
    "   $$\n",
    "   x^{(k+1)} = x^{(k)} - \\frac{f(x^{(k)})}{f'(x^{(k)})} \\left( \\frac{2}{2 - \\frac{f(x^{(k)}) f''(x^{(k)})}{f'(x^{(k)})^2}} \\right)\n",
    "   $$\n",
    "\n",
    "As vantagens do método de Halley sobre o método de Newton são a taxa de convergência e o alcance de uma solução mais precisa com menos iterações em comparação. Por outro lado, o cálculo das derivadas de ordem superior pode ser computacionalmente custoso e complexo, especialmente para funções complicadas. A precisão do método também depende da precisão das derivadas de segunda e terceira ordem. Portanto, erros nessas derivadas podem afetar a convergência e a precisão da solução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas propostos\n",
    "\n",
    "- Crie um código genérico que implemente o algoritmo do método de Newton de modo que a derivada seja calculada diretamenta por computação simbólica, sem intervenção manual, quando for possível. Dica: use `sympy.lambdify`.\n",
    "- Faça uma implementação do método de Newton para otimização e uma para o método de Halley. Em seguida, incorpore a capacidade de cálculo das derivadas de maneira automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.rcdefaults()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "LVMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}